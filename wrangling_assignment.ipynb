{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
   "metadata": {
    "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
   },
   "source": [
    "# Assignment: Data Wrangling\n",
    "## `! git clone https://github.com/DS3001/wrangling`\n",
    "## Do Q2, and one of Q1 or Q3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5735a4d4-8be8-433a-a351-70eb8002e632",
   "metadata": {
    "id": "5735a4d4-8be8-433a-a351-70eb8002e632"
   },
   "source": [
    "**Q1.** Open the \"tidy_data.pdf\" document in the repo, which is a paper called Tidy Data by Hadley Wickham.\n",
    "\n",
    "  1. Read the abstract. What is this paper about?\n",
    "  2. Read the introduction. What is the \"tidy data standard\" intended to accomplish?\n",
    "  3. Read the intro to section 2. What does this sentence mean: \"Like families, tidy datasets are all alike but every messy dataset is messy in its own way.\" What does this sentence mean: \"For a given dataset, itâ€™s usually easy to figure out what are observations and what are variables, but it is surprisingly difficult to precisely define variables and observations in general.\"\n",
    "  4. Read Section 2.2. How does Wickham define values, variables, and observations?\n",
    "  5. How is \"Tidy Data\" defined in section 2.3?\n",
    "  6. Read the intro to Section 3 and Section 3.1. What are the 5 most common problems with messy datasets? Why are the data in Table 4 messy? What is \"melting\" a dataset?\n",
    "  7. Why, specifically, is table 11 messy but table 12 tidy and \"molten\"?\n",
    "  8. Read Section 6. What is the \"chicken-and-egg\" problem with focusing on tidy data? What does Wickham hope happens in the future with further work on the subject of data wrangling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39b0ff-1abd-46df-82de-857198dfc3b4",
   "metadata": {},
   "source": [
    "RESPONSES:\n",
    "1. This paper discusses how data cleaning is an integral part of data science/analysis, and tidy datasets are a significant component in this process. A tidy dataset requires each variable to be a column, each observation a row, and each type of observational unit to be a table. Structuring the data in this way, according to Wickham, makes it easier to create tools to input/output this kind of data and perform analyses.\n",
    "2. The \"tidy data standard\" is intended to make data cleaning easier and more efficient by producing a standard organization for datasets - making it easier to produce/use tools for data analysis.\n",
    "3. The first sentence suggests that because messy datasets are unique in their structure/problems, it is easier to deal with tidy datasets that are all similar in order to make meaning out of the data. The second sentence describes how it may be simple to discern a row (observation) from a column (variable) in a dataset, but making comparisons or relationships between observations and variables can be difficult.\n",
    "4. Wickham explains that a dataset is a collection of values where a value is either a number or string that belongs to a variable. A variable is the collection of values measuring the same attribute (e.g., height). An observation is the values measured on the same unit across attributes (e.g., a person).\n",
    "5. In tidy data, each variable makes a column, each observation makes a row, and each type of observational unit makes a table.\n",
    "6. The five most common problems with messy datasets are (1) column headers are values instead of variable names, (2) multiple variables are stored in one column, (3) variables are stored in both rows and columns, (4) multiple types of observational units are stored in the same table, and (5) a single observational unit is stored in multiple tables. The data in Table 4 are messy because the column headers are actually values instead of variable names. In other words, the variables need to be transformed into their own columns (i.e., religion, income, and frequency need to be the three column headers in this dataset). This process is called melting - where columns are turned into rows. To melt this data, we would want to make income and frequency into their own columns. This results in a long dataset with each row being a type of religion, range of income, and frequency of values.\n",
    "7. Table 11 is a messy dataset because some column headers are values instead of variable names (e.g., \"d1\", \"d2\"... are values instead of variables) and there are multiple variables stored in one column (e.g., \"element\" stores both tmax and tmin). Table 12a melts this data by making the days values into a single \"date\" variable. A new column for \"value\" is also created. However, this is still not tidy because the \"element\" column does not contain values. In Table 12b, the values from the previous \"element\" column are split into two separate variables - \"tmax\" and \"tmin.\" This dataset is now tidy since each observation is a row and each variable is a column.\n",
    "8. The \"chicken-and-the-egg\" problem with tidy data is that tidy data is only as useful as the tools that come with it, but this therefore makes tidy tools linked to tidy data itself. Since tidy tools are designed to work specifically with tidy data, the two are consequently dependent on each other. For example, changing only the tidy tools may not make these processes more efficient as this would also require changing the tidy data structure. Wickham hopes that the tidy data framework will be a starting point for data scientists to build more efficient processes/tools for wrangling data, even outside of the concept of tidying."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30511981-a692-4b6d-a0bf-37a1b0933fcb",
   "metadata": {
    "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072"
   },
   "source": [
    "**Q2.** This question provides some practice cleaning variables which have common problems.\n",
    "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
    "2. Categorical variable: For the `./data/sharks.csv` data covered in the lecture, clean the \"Type\" variable as well as you can, and explain the choices you make.\n",
    "3. Dummy variable: For the pretrial data covered in the lecture, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, and, in particular, replace missing values with `np.nan`.\n",
    "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54cd0124-c2fe-40a0-a2df-cbbbbc14a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1720b609-379e-4609-bb9c-75aba314f8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Host Id</th>\n",
       "      <th>Host Since</th>\n",
       "      <th>Name</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Review Scores Rating (bin)</th>\n",
       "      <th>Room Type</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Number of Records</th>\n",
       "      <th>Number Of Reviews</th>\n",
       "      <th>Price</th>\n",
       "      <th>Review Scores Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5162530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 Bedroom in Prime Williamsburg</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>11249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33134899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunny, Private room in Bushwick</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private room</td>\n",
       "      <td>11206.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39608626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunny Room in Harlem</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Private room</td>\n",
       "      <td>10032.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>6/26/2008</td>\n",
       "      <td>Gorgeous 1 BR with Private Balcony</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>10024.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>6/26/2008</td>\n",
       "      <td>Trendy Times Square Loft</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Private room</td>\n",
       "      <td>10036.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>549</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Host Id Host Since                                Name Neighbourhood   \\\n",
       "0   5162530        NaN     1 Bedroom in Prime Williamsburg       Brooklyn   \n",
       "1  33134899        NaN     Sunny, Private room in Bushwick       Brooklyn   \n",
       "2  39608626        NaN                Sunny Room in Harlem      Manhattan   \n",
       "3       500  6/26/2008  Gorgeous 1 BR with Private Balcony      Manhattan   \n",
       "4       500  6/26/2008            Trendy Times Square Loft      Manhattan   \n",
       "\n",
       "  Property Type  Review Scores Rating (bin)        Room Type  Zipcode  Beds  \\\n",
       "0     Apartment                         NaN  Entire home/apt  11249.0   1.0   \n",
       "1     Apartment                         NaN     Private room  11206.0   1.0   \n",
       "2     Apartment                         NaN     Private room  10032.0   1.0   \n",
       "3     Apartment                         NaN  Entire home/apt  10024.0   3.0   \n",
       "4     Apartment                        95.0     Private room  10036.0   3.0   \n",
       "\n",
       "   Number of Records  Number Of Reviews Price  Review Scores Rating  \n",
       "0                  1                  0   145                   NaN  \n",
       "1                  1                  1    37                   NaN  \n",
       "2                  1                  1    28                   NaN  \n",
       "3                  1                  0   199                   NaN  \n",
       "4                  1                 39   549                  96.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Numeric variable: For ./data/airbnb_hw.csv, clean the Price variable as well as you can, and explain the choices you make. \n",
    "# How many missing values do you end up with? \n",
    "# (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
    "path = '/Users/Nata/Desktop/DS3001/wrangling/airbnb_hw.csv'\n",
    "\n",
    "airbnb = pd.read_csv(path, low_memory=False)\n",
    "airbnb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5abe63cd-6f98-48f1-a7e9-6ae52409a2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['145', '37', '28', '199', '549', '149', '250', '90', '270', '290',\n",
       "       '170', '59', '49', '68', '285', '75', '100', '150', '700', '125',\n",
       "       '175', '40', '89', '95', '99', '499', '120', '79', '110', '180',\n",
       "       '143', '230', '350', '135', '85', '60', '70', '55', '44', '200',\n",
       "       '165', '115', '74', '84', '129', '50', '185', '80', '190', '140',\n",
       "       '45', '65', '225', '600', '109', '1,990', '73', '240', '72', '105',\n",
       "       '155', '160', '42', '132', '117', '295', '280', '159', '107', '69',\n",
       "       '239', '220', '399', '130', '375', '585', '275', '139', '260',\n",
       "       '35', '133', '300', '289', '179', '98', '195', '29', '27', '39',\n",
       "       '249', '192', '142', '169', '1,000', '131', '138', '113', '122',\n",
       "       '329', '101', '475', '238', '272', '308', '126', '235', '315',\n",
       "       '248', '128', '56', '207', '450', '215', '210', '385', '445',\n",
       "       '136', '247', '118', '77', '76', '92', '198', '205', '299', '222',\n",
       "       '245', '104', '153', '349', '114', '320', '292', '226', '420',\n",
       "       '500', '325', '307', '78', '265', '108', '123', '189', '32', '58',\n",
       "       '86', '219', '800', '335', '63', '229', '425', '67', '87', '1,200',\n",
       "       '158', '650', '234', '310', '695', '400', '166', '119', '62',\n",
       "       '168', '340', '479', '43', '395', '144', '52', '47', '529', '187',\n",
       "       '209', '233', '82', '269', '163', '172', '305', '156', '550',\n",
       "       '435', '137', '124', '48', '279', '330', '5,000', '134', '378',\n",
       "       '97', '277', '64', '193', '147', '186', '264', '30', '3,000',\n",
       "       '112', '94', '379', '57', '415', '236', '410', '214', '88', '66',\n",
       "       '71', '171', '157', '545', '1,500', '83', '96', '1,800', '81',\n",
       "       '188', '380', '255', '505', '54', '33', '174', '93', '740', '640',\n",
       "       '1,300', '440', '599', '357', '1,239', '495', '127', '5,999',\n",
       "       '178', '348', '152', '242', '183', '253', '750', '259', '365',\n",
       "       '273', '197', '397', '103', '389', '355', '559', '38', '203',\n",
       "       '999', '141', '162', '333', '698', '46', '360', '895', '10', '41',\n",
       "       '206', '281', '449', '388', '212', '102', '201', '2,750', '4,750',\n",
       "       '432', '675', '167', '390', '298', '339', '194', '302', '211',\n",
       "       '595', '191', '53', '361', '480', '8,000', '4,500', '459', '997',\n",
       "       '345', '216', '218', '111', '735', '276', '91', '490', '850',\n",
       "       '398', '36', '775', '267', '625', '336', '2,500', '176', '725',\n",
       "       '3,750', '469', '106', '460', '287', '575', '227', '263', '25',\n",
       "       '228', '208', '177', '880', '148', '116', '685', '470', '217',\n",
       "       '164', '61', '645', '699', '405', '252', '319', '268', '419',\n",
       "       '343', '525', '311', '840', '154', '294', '950', '409', '184',\n",
       "       '257', '204', '241', '2,000', '412', '121', '288', '196', '900',\n",
       "       '647', '524', '1,750', '309', '510', '1,495', '1,700', '799',\n",
       "       '383', '372', '492', '327', '1,999', '656', '224', '173', '875',\n",
       "       '1,170', '795', '690', '146', '465', '1,100', '151', '274', '429',\n",
       "       '825', '282', '256', '1,111', '620', '271', '161', '51', '855',\n",
       "       '579', '1,174', '430', '20', '899', '649', '485', '181', '455',\n",
       "       '4,000', '243', '342', '590', '560', '374', '437', '232', '359',\n",
       "       '985', '31', '244', '254', '723', '237', '428', '370', '34',\n",
       "       '1,400', '580', '2,520', '221', '749', '1,600', '2,695', '306',\n",
       "       '202', '680', '570', '520', '223', '2,295', '213', '1,065', '346',\n",
       "       '24', '286', '296', '266', '26', '995', '1,368', '393', '182',\n",
       "       '635', '258', '780', '589', '347', '1,250', '1,350', '446',\n",
       "       '3,200', '1,050', '1,650', '1,550', '975', '323', '6,500', '2,499',\n",
       "       '1,850', '2,250', '715', '461', '540', '356', '439', '384', '569',\n",
       "       '1,900', '22', '785', '626', '830', '318', '444', '321', '401',\n",
       "       '1,499', '888', '369', '770', '386', '366', '344', '630', '313',\n",
       "       '597', '262', '509', '10,000', '278', '312', '789', '1,195', '422',\n",
       "       '21', '765', '3,500', '945', '326', '3,100', '2,486', '3,390',\n",
       "       '1,356', '2,599', '472', '454', '328', '396', '291'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb['Price'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8467c925-2d15-467e-974a-b982fa7ed0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# remove comma from values over 999 and convert to numeric so we can analyze this data properly\n",
    "price = airbnb['Price']\n",
    "price = price.str.replace(\",\",\"\")\n",
    "price.unique()\n",
    "price = pd.to_numeric(price, errors='coerce')\n",
    "missing = sum(price.isnull())\n",
    "print(missing) # no missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c8b08f-1669-49cf-86cb-99ad5b5557c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 246</th>\n",
       "      <th>Unnamed: 247</th>\n",
       "      <th>Unnamed: 248</th>\n",
       "      <th>Unnamed: 249</th>\n",
       "      <th>Unnamed: 250</th>\n",
       "      <th>Unnamed: 251</th>\n",
       "      <th>Unnamed: 252</th>\n",
       "      <th>Unnamed: 253</th>\n",
       "      <th>Unnamed: 254</th>\n",
       "      <th>Unnamed: 255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020.02.05</td>\n",
       "      <td>05-Feb-2020</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Maui</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stand-Up Paddle boarding</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020.01.30.R</td>\n",
       "      <td>Reported 30-Jan-2020</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>BAHAMAS</td>\n",
       "      <td>Exumas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Floating</td>\n",
       "      <td>Ana Bruna Avila</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020.01.17</td>\n",
       "      <td>17-Jan-2020</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Windang Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Will Schroeter</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020.01.16</td>\n",
       "      <td>16-Jan-2020</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>NEW ZEALAND</td>\n",
       "      <td>Southland</td>\n",
       "      <td>Oreti Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Jordan King</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020.01.13</td>\n",
       "      <td>13-Jan-2020</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Rodanthe, Dare County</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Samuel Horne</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   Case Number                  Date    Year        Type      Country  \\\n",
       "0      0    2020.02.05           05-Feb-2020  2020.0  Unprovoked          USA   \n",
       "1      1  2020.01.30.R  Reported 30-Jan-2020  2020.0    Provoked      BAHAMAS   \n",
       "2      2    2020.01.17           17-Jan-2020  2020.0  Unprovoked    AUSTRALIA   \n",
       "3      3    2020.01.16           16-Jan-2020  2020.0  Unprovoked  NEW ZEALAND   \n",
       "4      4    2020.01.13           13-Jan-2020  2020.0  Unprovoked          USA   \n",
       "\n",
       "              Area               Location                  Activity  \\\n",
       "0             Maui                    NaN  Stand-Up Paddle boarding   \n",
       "1           Exumas                    NaN                  Floating   \n",
       "2  New South Wales          Windang Beach                   Surfing   \n",
       "3        Southland            Oreti Beach                   Surfing   \n",
       "4   North Carolina  Rodanthe, Dare County                   Surfing   \n",
       "\n",
       "              Name  ... Unnamed: 246 Unnamed: 247 Unnamed: 248 Unnamed: 249  \\\n",
       "0              NaN  ...          NaN          NaN          NaN          NaN   \n",
       "1  Ana Bruna Avila  ...          NaN          NaN          NaN          NaN   \n",
       "2   Will Schroeter  ...          NaN          NaN          NaN          NaN   \n",
       "3      Jordan King  ...          NaN          NaN          NaN          NaN   \n",
       "4     Samuel Horne  ...          NaN          NaN          NaN          NaN   \n",
       "\n",
       "  Unnamed: 250 Unnamed: 251 Unnamed: 252 Unnamed: 253 Unnamed: 254  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "  Unnamed: 255  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Categorical variable: For the ./data/sharks.csv data covered in the lecture, \n",
    "# clean the \"Type\" variable as well as you can, and explain the choices you make.\n",
    "path = '/Users/Nata/Desktop/DS3001/wrangling/sharks.csv'\n",
    "\n",
    "sharks = pd.read_csv(path, low_memory=False)\n",
    "sharks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efd1fcf7-9d70-4a24-9b78-55d65102fac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unprovoked', 'Provoked', 'Questionable', 'Watercraft',\n",
       "       'Unconfirmed', 'Unverified', 'Invalid', 'Under investigation',\n",
       "       'Boating', 'Sea Disaster', nan, 'Boat', 'Boatomg'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharks['Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be523e9a-7f7d-4f7f-9741-e97fabd5789b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "Unprovoked             4716\n",
       "Provoked                593\n",
       "Invalid                 552\n",
       "Sea Disaster            239\n",
       "Watercraft              142\n",
       "Boat                    109\n",
       "Boating                  92\n",
       "Questionable             10\n",
       "Unconfirmed               1\n",
       "Unverified                1\n",
       "Under investigation       1\n",
       "Boatomg                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharks['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f1fcba-21b1-4b84-960c-eba6d0d1e78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type\n",
       "Unprovoked      4716\n",
       "Provoked         593\n",
       "Sea Disaster     583\n",
       "Questionable     565\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = sharks['Type']\n",
    "\n",
    "# consolidate categories -- especially questionable categories that only have a few values \n",
    "# this makes it easier to analyze the data \n",
    "types = types.replace(['Boat','Boating','Boatomg','Watercraft','Sea Disaster'],'Sea Disaster') \n",
    "types = types.replace(['Invalid', 'Questionable','Unconfirmed','Unverified','Under investigation'],'Questionable')\n",
    "\n",
    "sharks['Type'] = types\n",
    "del types\n",
    "\n",
    "sharks['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38065a4b-eda0-4890-88fa-70e8fcf2e8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InternalStudyID</th>\n",
       "      <th>REQ_REC#</th>\n",
       "      <th>Defendant_Sex</th>\n",
       "      <th>Defendant_Race</th>\n",
       "      <th>Defendant_BirthYear</th>\n",
       "      <th>Defendant_Age</th>\n",
       "      <th>Defendant_AgeGroup</th>\n",
       "      <th>Defendant_AgeatCurrentArrest</th>\n",
       "      <th>Defendant_AttorneyTypeAtCaseClosure</th>\n",
       "      <th>Defendant_IndigencyStatus</th>\n",
       "      <th>...</th>\n",
       "      <th>NewFelonySexualAssaultArrest_OffDate</th>\n",
       "      <th>NewFelonySexualAssaultArrest_ArrestDate</th>\n",
       "      <th>NewFelonySexualAssaultArrest_DaysBetweenContactEventandOffDate</th>\n",
       "      <th>NewFelonySexualAssaultArrest_DaysBetweenOffDateandArrestDate</th>\n",
       "      <th>NewFelonySexualAssaultArrest_DaysBetweenReleaseDateandOffDate</th>\n",
       "      <th>NewFelonySexualAssaultArrest_Disposition</th>\n",
       "      <th>Intertnalindicator_ReasonforExcludingFromFollowUpAnalysis</th>\n",
       "      <th>CriminalHistoryRecordsReturnedorCMSRecordsFoundforIndividual</th>\n",
       "      <th>DispRecordFoundforChargesinOct2017Contact_Atleast1dispfound</th>\n",
       "      <th>CrimeCommission2021ReportClassificationofDefendants</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADI00001</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>1986</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Defendant could not be classified or tracked d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADI00007</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>1956</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Defendant Detained Entire Pre-Trial Period_Und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADI00008</td>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>W</td>\n",
       "      <td>1990</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Defendant Detained Entire Pre-Trial Period_Und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CDI00036</td>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>1989</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Defendant Detained Entire Pre-Trial Period_Und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CDI00038</td>\n",
       "      <td>7</td>\n",
       "      <td>F</td>\n",
       "      <td>W</td>\n",
       "      <td>1988</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>New criminal offense punishable by incarcerati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 709 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  InternalStudyID REQ_REC# Defendant_Sex Defendant_Race Defendant_BirthYear  \\\n",
       "0        ADI00001        1             M              W                1986   \n",
       "1        ADI00007        3             M              B                1956   \n",
       "2        ADI00008        4             M              W                1990   \n",
       "3        CDI00036        6             M              B                1989   \n",
       "4        CDI00038        7             F              W                1988   \n",
       "\n",
       "  Defendant_Age  Defendant_AgeGroup Defendant_AgeatCurrentArrest  \\\n",
       "0            31                   3                           31   \n",
       "1            60                   6                           60   \n",
       "2            27                   3                           27   \n",
       "3            27                   3                           27   \n",
       "4            28                   3                           28   \n",
       "\n",
       "   Defendant_AttorneyTypeAtCaseClosure  Defendant_IndigencyStatus  ...  \\\n",
       "0                                   99                         99  ...   \n",
       "1                                    9                          9  ...   \n",
       "2                                    9                          9  ...   \n",
       "3                                    0                          0  ...   \n",
       "4                                    0                          0  ...   \n",
       "\n",
       "  NewFelonySexualAssaultArrest_OffDate  \\\n",
       "0                                        \n",
       "1                                        \n",
       "2                                        \n",
       "3                                        \n",
       "4                                        \n",
       "\n",
       "  NewFelonySexualAssaultArrest_ArrestDate  \\\n",
       "0                                           \n",
       "1                                           \n",
       "2                                           \n",
       "3                                           \n",
       "4                                           \n",
       "\n",
       "   NewFelonySexualAssaultArrest_DaysBetweenContactEventandOffDate  \\\n",
       "0                                                                   \n",
       "1                                                                   \n",
       "2                                                                   \n",
       "3                                                                   \n",
       "4                                                                   \n",
       "\n",
       "  NewFelonySexualAssaultArrest_DaysBetweenOffDateandArrestDate  \\\n",
       "0                                                999             \n",
       "1                                                999             \n",
       "2                                                999             \n",
       "3                                                999             \n",
       "4                                                999             \n",
       "\n",
       "   NewFelonySexualAssaultArrest_DaysBetweenReleaseDateandOffDate  \\\n",
       "0                                                999               \n",
       "1                                                999               \n",
       "2                                                999               \n",
       "3                                                999               \n",
       "4                                                999               \n",
       "\n",
       "   NewFelonySexualAssaultArrest_Disposition  \\\n",
       "0                                             \n",
       "1                                             \n",
       "2                                             \n",
       "3                                             \n",
       "4                                             \n",
       "\n",
       "   Intertnalindicator_ReasonforExcludingFromFollowUpAnalysis  \\\n",
       "0                                                  4           \n",
       "1                                                  5           \n",
       "2                                                  5           \n",
       "3                                                  5           \n",
       "4                                                  0           \n",
       "\n",
       "   CriminalHistoryRecordsReturnedorCMSRecordsFoundforIndividual  \\\n",
       "0                                                  1              \n",
       "1                                                  1              \n",
       "2                                                  1              \n",
       "3                                                  1              \n",
       "4                                                  1              \n",
       "\n",
       "  DispRecordFoundforChargesinOct2017Contact_Atleast1dispfound  \\\n",
       "0                                                  0            \n",
       "1                                                  1            \n",
       "2                                                  1            \n",
       "3                                                  1            \n",
       "4                                                  1            \n",
       "\n",
       "   CrimeCommission2021ReportClassificationofDefendants  \n",
       "0  Defendant could not be classified or tracked d...    \n",
       "1  Defendant Detained Entire Pre-Trial Period_Und...    \n",
       "2  Defendant Detained Entire Pre-Trial Period_Und...    \n",
       "3  Defendant Detained Entire Pre-Trial Period_Und...    \n",
       "4  New criminal offense punishable by incarcerati...    \n",
       "\n",
       "[5 rows x 709 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Dummy variable: for pretrial data, clean WhetherDefendantWasReleasedPretrial` variable as well as you can, \n",
    "# and, in particular, replace missing values with `np.nan`.\n",
    "\n",
    "path = '/Users/Nata/Desktop/DS3001/wrangling/justice_data.parquet'\n",
    "\n",
    "pretrial = pd.read_parquet(path, engine='pyarrow')\n",
    "pretrial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f306bf92-546a-499d-98ab-baf20624c2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrial['WhetherDefendantWasReleasedPretrial'].unique()\n",
    "# from codebook: \n",
    "    # Not released 0\n",
    "    # Released 1\n",
    "    # Unclear 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf65b421-e46c-4635-ad36-979d4eb87026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WhetherDefendantWasReleasedPretrial\n",
       "1    19154\n",
       "0     3801\n",
       "9       31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrial['WhetherDefendantWasReleasedPretrial'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f144030-99b0-4745-8565-6daa8eef01c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "WhetherDefendantWasReleasedPretrial\n",
      "1.0    19154\n",
      "0.0     3801\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labels = pretrial['WhetherDefendantWasReleasedPretrial']\n",
    "\n",
    "# replace type 9 with NaN\n",
    "labels = labels.replace([9],np.nan)\n",
    "NAs = sum(labels.isnull())\n",
    "\n",
    "pretrial['WhetherDefendantWasReleasedPretrial'] = labels\n",
    "del labels\n",
    "\n",
    "counts = pretrial['WhetherDefendantWasReleasedPretrial'].value_counts()\n",
    "print(NAs)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a00c7d96-ea7c-4103-846e-9cd3acbf2859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Missing values, not at random: For the pretrial data covered in the lecture, \n",
    "# clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. \n",
    "# (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abe1584a-23d4-4db8-af19-b8ef9adf411d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 1, 4, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrial['SentenceTypeAllChargesAtConvictionInContactEvent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71de1a38-5cd8-468b-8c01-cc121312958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9053\n",
      "274\n"
     ]
    }
   ],
   "source": [
    "sentences = pretrial['ImposedSentenceAllChargeInContactEvent']\n",
    "types = pretrial['SentenceTypeAllChargesAtConvictionInContactEvent']\n",
    "# from codebook: \n",
    "    # Probation/no incarceration: 0\n",
    "    # Jail up to 12 months: 1\n",
    "    # Prison (one year or more): 2\n",
    "    # Other, all charges in cohort contact resulted in pending, dismissed, deferred, etc.: 4\n",
    "    # Not applicable (e.g., disposition record not found, or unknown): 9\n",
    "sentences = pd.to_numeric(sentences,errors='coerce') # first coerce values to numeric \n",
    "NAs = sum(sentences.isnull())\n",
    "print(NAs)\n",
    "sentences = sentences.replace(\" \", np.nan) # some values are just \" \", make these NaN \n",
    "sentences = sentences.mask(types == 4,0) # type 4 corresponds to charges that resulted in pending/dismissed, make these 0 \n",
    "sentences = sentences.mask(types == 9,np.nan) # type 9 corresponds to NAs, make these NaN \n",
    "NAs = sum(sentences.isnull())\n",
    "print(NAs)\n",
    "\n",
    "pretrial['ImposedSentenceAllChargeInContactEvent'] = sentences\n",
    "del sentences, types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5",
   "metadata": {
    "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5"
   },
   "source": [
    "**Q3.** Many important datasets contain a race variable, typically limited to a handful of values often including Black, White, Asian, Latino, and Indigenous. This question looks at data gathering efforts on this variable by the U.S. Federal government.\n",
    "\n",
    "1. How did the most recent US Census gather data on race?\n",
    "2. Why do we gather these data? What role do these kinds of data play in politics and society? Why does data quality matter?\n",
    "3. Please provide a constructive criticism of how the Census was conducted: What was done well? What do you think was missing? How should future large scale surveys be adjusted to best reflect the diversity of the population? Could some of the Census' good practices be adopted more widely to gather richer and more useful data?\n",
    "4. How did the Census gather data on sex and gender? Please provide a similar constructive criticism of their practices.\n",
    "5. When it comes to cleaning data, what concerns do you have about protected characteristics like sex, gender, sexual identity, or race? What challenges can you imagine arising when there are missing values? What good or bad practices might people adopt, and why?\n",
    "6. Suppose someone invented an algorithm to impute values for protected characteristics like race, gender, sex, or sexuality. What kinds of concerns would you have?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
